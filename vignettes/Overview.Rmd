---
title: "Overview of CNPBayes package"
author: "Jacob Carey, Steven Cristiano, and Robert Scharpf"
date: \today
output: BiocStyle::pdf_document
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{Overview of CNPBayes package}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc} 
---

# Introduction

CNPBayes models multi-modal densities via a hierarchical Bayesian
Gaussian mixture model.  The major application of this model is the
estimation of copy number at copy number polymorphic loci (CNPs). Two
versions of the mixture model are implemented.  A *standard* model,
referred to as a *marginal* model, that has one mean and standard
deviation for each component, and a *batch* model with batch-specific
means and standard deviations. Approximation of the posterior is by
Markov Chain Monte Carlo (MCMC) written in C++ using the Rcpp package
[@Rcpp].  

For an EM-implementation of Gaussian mixture models for CNPs, see the
Bioconductor package CNVtools [@Barnes2008].  A Bayesian extension of
this model by some of the same authors was developed to automate the
analysis of the Welcome Trust Case Control Consortium (WTCCC) genotype
data [@cardin] and implemented in the R package CNVCALL
(http://niallcardin.com/CNVCALL).

This vignette provides a concise workfklow for fitting mixture models
in large array-based genome-wide association studies.  We refer the
reader to other vignettes included with this package for details
regarding implementation.

```{r lib} 
library(CNPBayes)
library(SummarizedExperiment)
```

# Workflow

## Delineate CNPs for each ancestry group

Provided in the `CNPBayes` package is example `SnpArrayExperiment` and `GRangesList` data.

```{r find_cnps}
se <- readRDS(system.file("extdata", "simulated_se.rds", package="CNPBayes"))
grl <- readRDS(system.file("extdata", "grl_deletions.rds", package="CNPBayes"))
```

Using this data, we identify CNP loci and summarize within sample and locus by median.

```{r summary, message=FALSE}
cnv.region <- consensusCNP(grl, max.width=5e6)
i <- subjectHits(findOverlaps(cnv.region, rowRanges(se)))
med.summary <- matrixStats::colMedians(assays(se)[["cn"]][i, ], na.rm=TRUE)
```

See [Identifying Copy Number Polymorphisms](FindCNPs.pdf) for instructions on finding CNPs with a `SnpArrayExperiment` and `GRangesList`.

A `MixtureModel` is constructed using this summarized data for a CNP locus with
a call to `MarginalModel` or `BatchModel`, depending on whether the simulation
should be *marginal* across batch effect, or *hierarchical*. The batch of a
subject is determined by the chemistry plate and is specified using the `batch`
parameter in the `BatchModel`. Multiple chemistry plates can be grouped in a
single batch using the function `collapseBatch`. However, as there are only 35
samples in this toy example, we assume that these samples were all processed in
the same batch. For illustration, we demonstrate how one could construct a
`BatchModel` with two batches, but we do not try to run MCMC on this object.

```{r model_construction}
mp <- McmcParams(nStarts=10, burnin=200, iter=200)
set.seed(1337)
sb.list <- MarginalModelList(data=med.summary, mcmc.params=mp, k=1:4)
mb.list <- BatchModelList(data=med.summary, k=1:4,
                          batch=c(rep(1, 12), rep(2, 23)),
                          mcmc.params=mp)
```

For details about model construction and other optional parameters, see [Bayesian mixture models for copy number estimation](Implementation.pdf).

## Fitting mixture models at each CNP

For array-based estimates and germline genomes, there are typically
between 1 and 4 copy number states at any given CNP.  Since we do not
know the number of components a priori, we fit a model for each k.
In addition, we fit models with and without a term for batch.

The `posteriorSimulation` function takes a constructed `MixtureModel` and `k`, a
vector of the number of components for which to fit models. The posterior
simulations of each model is held in a list. MCMC simulations for the batch
model (not evaluated) have the same interface. Warnings regarding label
switching can indidate that the burnin is insufficient, or that the model is
overfit. Here, there are clearly only 2 components but we proceeed with the
overfit models.

```{r posteriorSimulation}
set.seed(13)
sb.list <- posteriorSimulation(sb.list)
mb.list <- posteriorSimulation(mb.list)
```

## Selecting a model

Marginal likelihood is estimated for each of the 4 single-batch models. The
Bayes' factor is used to select one of these models for further study. Had we
fit the multi-batch models, one could compare the marginal likelihoods between
the single-batch and multi-batch models to determine the best fit.

```{r likelihood}
## marginal likelihood of each model
ml.lik <- c(marginalLikelihood(sb.list),
            marginalLikelihood(mb.list))
best.model <- names(ml.lik)[which.max(ml.lik)]
best.model
```

## Mapping mixture components to copy number assignments

The model selected by the above procedure may not necessarily have mixture
components that correspond to distinct copy number states. For example, if there
are not many probes in a CNP region the average log R ratios are more likely to
be skewed. See also the discussion in [@cardin]. Following model selection, we
map mixture components to distinct copy number states. Our assumption in this
step is that if we fit a skewed distribution with more than 1 Gaussian
components, those Guassian mixture components should have substantial overlap as
evidenced by a large number of observations with posterior probabilities in the
interval [c, 1-c]. The `mapParams` function specifies parameters for determining
whether two components should be considered a single copy number state or
multiple states.

```{r map_distinct}
cn.model <- SingleBatchCopyNumber(best.model)
mapping(cn.model) <- mapComponents(cn.model)
## posterior probabilities for copy number states
head(probz(cn.model))
```

For a `SingleBatchCopyNumber` instance, posterior probabilities are derived for
 distinct copy number states (not mixture components). When there is a
 one-to-one mapping between mixture components and copy number, the posterior
 probabilities are identical. Had the mapping step produced a many-to-one
 mapping from mixture components to copy number, the posterior probabilities are
 added for components that correspond to the same copy number. To make this
 obvious, below we map both mixture components to a single state and recompute
 the copy number probabilities.

```{r posterior_prob}
mapping(cn.model) <- c(1, 1)
head(probz(cn.model))
```
  
## Extracting MAP estimates and posterior probabilities

For the selected model, we can view the *maximum a posteriori* estimates for
component.
```{r map}
selected.model <- sb.list[[2]]
map(selected.model)
```

We can plot the average log R ratios and overlay the model-based densities:

```{r ggsinglebatch}
ggSingleBatch(selected.model)
```

# References

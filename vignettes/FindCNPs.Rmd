---
title: "Identifying Copy Number Polymorphisms"
author: "Jacob Carey, Steven Cristiano, and Robert Scharpf"
date: \today
output: BiocStyle::pdf_document
vignette: >
  %\VignetteIndexEntry{Identifying Copy Number Polymorphisms}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc} 
---

# Introduction

Identify consensus start and stop coordinates of a copy number
polymorphism

The collection of copy number variants (CNVs) identified in a study
can be encapulated in a GRangesList, where each element is a GRanges
of the CNVs identified for an individual.  (For a study with 1000
subjects, the GRangesList object would have length 1000 if each
individual had 1 or more CNVs.)  For regions in which CNVs occur in
more than 2 percent of study participants, the start and end
boundaries of the CNVs may differ because of biological differences in
the CNV size as well as due to technical noise of the assay and the
uncertainty of the breakpoints identified by a segmentation of the
genomic data.  Among subjects with a CNV called at a given locus, the
`consensusCNP` function identifies the largest region that is copy
number variant in half of these subjects.

# Finding CNPs
Included in the CNPBayes package are objects of class `SnpArrayExperiment`
and `GRangesList`. We begin by loading the necessary libraries and data.

```{r prelim}
knitr::opts_chunk$set(eval=FALSE)
library(CNPBayes)
library(VanillaICE)
se <- readRDS(system.file("extdata", "simulated_se.rds", package="CNPBayes"))
grl <- readRDS(system.file("extdata", "grl_deletions.rds", package="CNPBayes"))
```

The object `se` contains log R ratios and B Allele Frequencies, and the object
`grl` is a `GRangesList` of simulated deletions. 

After reading this saved data, we visualize the CNVs.

```{r plot-cnvs}
trellis_param <- HmmTrellisParam()
cnvList <- split(cnvs, cnvs$id)
figList <- xyplotList(cnvList, snp_exp, trellis_param)

figList <- xyplotList(grl, se[, 1:25])
```

# One Dimensional Summary

Before further analysis can be performed, the log R ratios in a CNV region must
be summarized to a one dimensional object. 
Before a `MixtureModel` can be fit, the log R ratios must be summarized. One
method for summary is to use the first principal component to summarize the log
R ratios. A possible disadvantage of this approach is that the scale of the
loadings makes it more difficult to interpret the copy number of the mixture
components. Instead, the median log R ratio is adequate and retains the
original scale.

To summarize samples by the median log R ratios, we define the largest region
that spans 50 percent of the samples using the function `consensusCNP`. Because
the deletions in this example are large (great than 2 Mb), we specify a large
value for `max.width` to avoid filter ing these CNVs.

** Summaries

To summarize the log R ratios in the CNV regions, one could find the
markers for the entire region and use the first principal component
(PC) to summarize the log R ratios as advocated by Cardin \textit{et
al}.  The potential disadvantage of this approach is that the scale of
the loadings makes it more difficult to interpret the copy number of
the mixture components.  Often the median log R ratio is adequate, and
retains the original scale.

*** Median summary

To summarize samples by the median log R ratios, we define the largest
region that spans 50 percent of the samples using the function
~consensusCNP~.  Because the deletions in this example are large ($>$
2Mb), we specify a large value for ~max.width~ to avoid filtering
these CNVs.

A median summary of the log R ratios for each sample is straight
forward.  

*** PC summary

An advantage of PC is that we can simply use the minimum start and
maximum end to define the CNV region -- PC should automatically
downweight markers that are not consistent with the CNV. 

# Median

# PCA

```{r summary}
# median
cnv.region <- consensusCNP(grl, max.width=5e6)
i <- subjectHits(findOverlaps(cnv.region, se))
med.summary <- matrixStats::colMedians(lrr(se)[i, ], na.rm=TRUE)

# PCA
cnv.region2 <- reduce(grl)
i.pc <- subjectHits(findOverlaps(cnv.region2, se))
x <- lrr(se)[i.pc, ]
nas <- rowSums(is.na(x))
na.index <- which(nas > 0)
x <- x[-na.index, , drop=FALSE]
pc.summary <- prcomp(t(x))$x[, 1]
meds.for.pc <- matrixStats::colMedians(x, na.rm=TRUE)
if(cor(pc.summary, meds.for.pc) < 1) pc.summary <- -1*pc.summary
```

Finally we plot the one dimensional summaries.

```{r summary-plots}
par(mfrow=c(1,2), las=1)
plot(med.summary, main="median summary of\nconsensus CNP", cex.main=0.7, pch=20)
plot(pc.summary, main="PC summary of\nreduced CNV ranges", cex.main=0.7, pch=20)
```

Please refer to the CNPBayes vignette for fitting a `MixtureModel`.

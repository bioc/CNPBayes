---
title: "Bayesian mixture models for copy number estimation"
author: 
- Jacob Carey
- Robert Scharpf
- Steven Cristiano
date: \today
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Bayesian mixture models for copy number estimation}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc} 
---

# Introduction

CNPBayes allows for copy number estimation via a Bayesian mixture model. Models
can be marginal or hierarchical over batches. The long-running, Markov Chain
Monte Carlo portions of the code are written in C++ (using Rcpp) for fast
performance.

# posteriorSimulation

In order to simulate the posterior distribution of a model, many parameters for
the routine must be specified first. An instance of class `McmcParams` is used
to specify the simulation options, such as number of iterations, length of
burnin, and thinning interval.
```{r McmcParams}
mp <- McmcParams(iter=1000,
                 burnin=100,
                 thin=1)
```
- McmcParams()
- Hyperparameters()
- graphical model
- MarginalModel
- BatchModel
- visualization (DensityModel/plot)
- merging (if needed)

# K unknown

- computeMarginalLik
    - Ref Chib estimator / Berkhof for estimating marginal likelihoods
- computing a bayes factor
- merging components
- Alternative statistics for model selection (i.e., BIC)

# Finding CNPs
- hidden Markov models
- prior knowledge (HapMap / 1000 Genomes Project)

# Other applications
- down-sampling 
- modeling differences in variance (same mean)
   - paramUpdates





---
title: "Bayesian mixture models for copy number estimation"
author: "Jacob Carey, Robert Scharpf, and Steven Cristiano"
date: \today
output: BiocStyle::pdf_document
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{Bayesian mixture models for copy number estimation}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc} 
---

# Introduction

CNPBayes allows for copy number estimation via a Bayesian mixture model. Models
can be marginal or hierarchical over batches. The long-running, Markov Chain
Monte Carlo portions of the code are written in C++ using Rcpp [@Rcpp] for fast
performance.

```{r lib}
library(CNPBayes)
```

# posteriorSimulation

## MarginalModel
### McmcParams

In order to simulate the posterior distribution of a model, many parameters for
the routine must be specified first. An instance of class `McmcParams` is used
to specify the simulation options, such as number of iterations, length of
burnin, and thinning interval.
```{r McmcParams}
mp <- McmcParams(iter=1000,
                 burnin=100,
                 thin=1)
```

### Hyperparameters

Hyperparameters for the mixture model are specified as an instance of class
`Hyperparameters`. Hyperparameters include:  

- `k` the number of components (or copy numbers). Defaults to 2.  

- `mu.0` and `tau2.0` priors for $\mu \sim \text{N(mu.0, tau2.0)}$, the 
  overall mean of components. Default to 0 and 100 respectively.  

- `eta.0` and `m2.0` priors for 
  $\tau^2 \sim \text{Ga(rate=eta.0, shape=m2.0)}$, the overall variance across
  components. Default to 1 and 0.1 respectively for marginal models and 1800
  and 1/60 respectively for batch models.  

- `alpha` the prior mixture probabilities. Does not have to sum to 1. By
  default, a noninformative prior of equal mixtures is used.  

- `beta` prior for $\nu_0$. Defaults to 0.1.  

- `a` and `b` priors for $\sigma^2_0 \sim \text{Ga(shape=a, rate=b)}$, the rate
  parameter for $\sigma^2$, the variance for each batch and component.  

```{r graph-marginal, echo=FALSE}
library(grid)
bayesianGrob <- function(x, r=unit(0.25, "inches")){
  tg <- textGrob(x)
  cg <- circleGrob(r=r)
  boxedText <- gTree(children=gList(tg, cg))
}

grobY <- bayesianGrob(expression(y[i]))
grobThetas <- bayesianGrob(expression(theta[h]))
grobSigma2 <- bayesianGrob(expression(sigma[h]^2))
grobH <- bayesianGrob(expression(z[i]))
grobNu0 <- bayesianGrob(expression(nu[0]))
grobSigma02 <- bayesianGrob(expression(sigma[0]^2))
grobPi <- bayesianGrob(expression(pi[h]))
grobMu <- bayesianGrob(expression(mu[h]))
grobTau2 <- bayesianGrob(expression(tau[h]^2))

h <- unit(0.25, "inches")
e <- unit(0.05, "inches")
d <- unit(0.025, "inches")

ar <- arrow(ends="last", length=unit(0.075, "inches"), type="closed")
grid.newpage()
y.x <- 0.5; y.y <- 0.1
h.x <- 0.1; h.y <- 0.3
theta.x <- 0.5; theta.y <- 0.3
sigma2.x <- 0.7; sigma2.y <- 0.3
pi.x <- 0.1; pi.y <- 0.5
mu.x <- 0.45; mu.y <- 0.5
tau2.x <- 0.55; tau2.y <- 0.5
nu0.x <- 0.65; nu0.y <- 0.5
s20.x <- 0.75; s20.y <- 0.5
grid.draw(editGrob(grobY, vp=viewport(y.x, y.y), gp=gpar(fill="gray")))
grid.draw(editGrob(grobY, vp=viewport(y.x, y.y), gp=gpar(fill="transparent")))
grid.draw(editGrob(grobH, vp=viewport(h.x, h.y)))

grid.draw(editGrob(grobThetas, vp=viewport(theta.x, theta.y)))
grid.draw(editGrob(grobSigma2, vp=viewport(sigma2.x, sigma2.y)))

## theta -> y
grid.move.to(unit(theta.x, "npc"), unit(theta.y, "npc") - h)
grid.line.to(unit(y.x, "npc"), unit(y.y, "npc") + h, arrow=ar,
             gp=gpar(fill="black"))
## sigma2 -> y
grid.move.to(unit(sigma2.x, "npc") - e, unit(sigma2.y, "npc") -h)
grid.line.to(unit(y.x, "npc") + h, unit(y.y, "npc") + h, arrow=ar,
             gp=gpar(fill="black"))

## h -> theta
grid.move.to(unit(h.x, "npc") + h, unit(h.y, "npc") - h)
grid.line.to(unit(y.x, "npc") - h, unit(y.y, "npc") + h,  arrow=ar,
             gp=gpar(fill="black"))

##pi
grid.draw(editGrob(grobPi, vp=viewport(pi.x, pi.y)))
## pi -> h
grid.move.to(x=unit(pi.x, "npc"), y=unit(pi.y, "npc") - h)
grid.line.to(x=unit(h.x, "npc"),
             y=unit(h.y, "npc")+h, arrow=ar,
             gp=gpar(fill="black"))


## mu_h
grid.draw(editGrob(grobMu, vp=viewport(mu.x, mu.y)))
## mu_h -> theta
grid.move.to(x=unit(mu.x, "npc")+e, y=unit(mu.y, "npc") - h)
grid.line.to(x=unit(theta.x, "npc")-e, y=unit(theta.y, "npc")+h, arrow=ar,
             gp=gpar(fill="black"))


## sigma2_h
grid.draw(editGrob(grobTau2, vp=viewport(tau2.x, tau2.y)))
## sigma2_h -> theta_h
grid.move.to(x=unit(tau2.x, "npc")-e, y=unit(tau2.y, "npc") - h)
grid.line.to(x=unit(theta.x, "npc")+e, y=unit(theta.y, "npc")+h, arrow=ar,
             gp=gpar(fill="black"))

grid.draw(editGrob(grobNu0, vp=viewport(nu0.x, nu0.y)))
## nu_0 -> sigma2_0
grid.move.to(x=unit(nu0.x, "npc")+e, y=unit(nu0.y, "npc") - h)
grid.line.to(x=unit(sigma2.x, "npc")-e, y=unit(sigma2.y, "npc")+h, arrow=ar,
             gp=gpar(fill="black"))

grid.draw(editGrob(grobSigma02, vp=viewport(s20.x, s20.y)))
## nu_0 -> sigma2_0
grid.move.to(x=unit(s20.x, "npc")-e, y=unit(s20.y, "npc") - h)
grid.line.to(x=unit(sigma2.x, "npc")+e, y=unit(sigma2.y, "npc")+h, arrow=ar,
             gp=gpar(fill="black"))
```

Constructing an instance of class `Hyperparameters` for a `MarginalModel` can
be performed as follows.
```{r Hyperparameters}
hypp <- Hyperparameters(type="marginal", k=3)
```

### simulateData

CNPBayes also allows for the simulation of test data. The number of
observations, means for each component, standard deviations for each component,
and mixture proportions must be specified. 
```{r simulateData}
sim.data <- simulateData(N=2500, p=rep(1/3, 3),
                         theta=c(-1, 0, 1),
                         sds=rep(0.1, 3))
```

### posteriorSimulation

To simulate the posterior distribution, an instance of class MarginalModel or
must first be constructed. Note that when initializing objects of these 
classes, the parameters `data`, `k` (number of *a priori* components), 
`hypp`, (object of class `Hyperparameters`) and `mcmc.params` (object of class
`McmcParams`) should be specified. Default values for `hypp` and `mcmc.params`
will be used if not specified. Note that to retrieve the simulated data from
the object, the `y` method can be used. After construction of a model, the
`posteriorSimulation` method should be used.

```{r model}
model <- MarginalModel(data=y(sim.data), k=3,
                       hypp=hypp,
                       mcmc.params=mp)

model <- posteriorSimulation(model)
```

The results of a `DensityModel` call returns an object of class
`DensityModel`. This object can be used, along with the data, for plotting.

```{r plot}
plot(DensityModel(model), y(sim.data), 
     main="Marginal Model posterior")
```

## BatchModel

In general, the construction and simulation of a `BatchModel` is similar to
that of a `MarginalModel`. The `BatchModel` is hierarchical over the batches,
and thus requires information about the batches. Instances of `McmcParams` are
equivalent between `BatchModel` and `MarginalModel`. However, an object of
class `Hyperparameters` is constructed with a `type` of "batch". Additionally,
simulated batch data is created using `simulateBatchData` which requires
`theta` and `sds` to be specifed as $K \times B$ matrices, for $K$ components
and $B$ batches. `simulateBatchData` also requires a `batch` parameter,
labelling the batch of each observation. Finally, `BatchModel`s are constructed
using the function `BatchModel` which operates similarly to `MarginalModel` but
requires a `batch` parameter, similar to `Hyperparameters`. `plot`s of 
`BatchModel`s include batch specific density estimates.

```{r batch}
## Create Hyperparameters for batch model
hypp <- Hyperparameters(type="batch", k=3)

## simulate batch data
k <- 3
nbatch <- 3
means <- matrix(c(-1.2, -1.0, -0.8,
                -0.2, 0, 0.2,
                0.8, 1, 1.2), nbatch, k, byrow=FALSE)
sds <- matrix(0.1, nbatch, k)
N <- 1500
sim.data <- simulateBatchData(N=N,
                              batch=rep(letters[1:3], length.out=N),
                              theta=means,
                              sds=sds,
                              p=c(1/5, 1/3, 1-1/3-1/5))

# create BatchModel and run posteriorSimulation
model <- BatchModel(data=y(sim.data), k=3,
                    batch=rep(letters[1:3], length.out=N),
                    hypp=hypp,
                    mcmc.params=mp)

model <- posteriorSimulation(model)
plot(model)
```

# K unknown

Often times, the number of components is not known $a priori$. In order to
estimate the number, the `computeMarginalLik` function is used. 

```{r computeMarginalLik}
x <- computeMarginalLik(y(sim.data), K=2:3)
orderModels(x)
```

It is worth noting that `computeMarginalLik` is the most computationally
intensive routine included in `CNPBayes`. In spite of the most resource
expensive portions being coded in C++, this procedure can still be time
consuming, especially for batch data. In part this is because, by default, 3
sequential instances of 10 `posteriorSimulation`s are run for each possible
number of latent variables. Additionally, for each number of components, the
mode of $\theta$ is identified, fixed, and the MCMC simulation is run again.
After this simulation, the process is repeated, but with $\sigma^2$ being
integrated over. While the marginal likelihood is computed and used for 
determining *k*, the number of latent variable, Chib's Estimator [@chib] and a 
variant of Chib's Estimator [@berkhof] is also calculated. The log Bayes Factor
is computed comparing the two models with the highest marginal likelihood.

```{r bayesFactor}
logBayesFactor(x)
```

Alternative methods for selection of *k* are also included. As an example, the
`bic` method can be used for calculating the Bayesian Information Criterion. 

```{r bic}
## simulate k=2 model
sim.data <- simulateData(N=2500, p=rep(1/3, 3),
                         theta=c(-1, 0, 1),
                         sds=rep(0.1, 3))
hypp1 <- Hyperparameters(k=2)
m1 <- MarginalModel(data=y(sim.data), k=2,
                    hypp=hypp1,
                    mcmc.params=mp)
m1 <- posteriorSimulation(m1)

## simulate k=3 model
hypp2 <- Hyperparameters(k=3)
m2 <- MarginalModel(data=y(sim.data), k=3,
                    hypp=hypp2,
                    mcmc.params=mp)
m2 <- posteriorSimulation(m2)

bic(m1)
bic(m2)
```

As the data is simulated from a three component distribution, `m2` should be
chosen. Using the Bayesian Information Criterion, the correct model is chosen
in this simple example.

Finally, in an overfit model (one with too many components), merging components
is supported. This merging procedure also ensures 

```{r merge}
model <- MarginalModel(data=y(sim.data), k=4,
                       hypp=Hyperparameters(k=4),
                       mcmc.params=mp)
model <- posteriorSimulation(model)
dm <- DensityModel(model)
modes(dm)
dm_merged <- DensityModel(model, merge=TRUE)
k(dm_merged)

par(mfrow=c(1,2), las=1)
plot(dm, y(sim.data))
plot(dm_merged, y(sim.data))
```

This merging procedure also ensures that there is no underfitting. For example,
merging a model with three true components will yield a model with three
components.

```{r merge-under}
model <- MarginalModel(data=y(sim.data), k=3,
                       hypp=Hyperparameters(k=3),
                       mcmc.params=mp)
model <- posteriorSimulation(model)
dm <- DensityModel(model)
dm_merged <- DensityModel(model, merge=TRUE)
k(dm)
k(dm_merged)
```

A lot of the work for merging is in CNVTools. Can capture
skewness with modeling batch. Can we simulate something that shows this well?
If you have three batches, and two components (three means for hemizygous and
three means for diploid). won't be quite normal, skewed/asymmetric. 

# References
